#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LoRA + RoPE è®­ç»ƒè„šæœ¬ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨train_lora_rope.pyè¿›è¡Œæ¨¡å‹è®­ç»ƒ
"""

import os
import sys
from pathlib import Path

def show_usage_example():
    """æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹"""
    print("=" * 60)
    print("ğŸš€ LoRA + RoPE è®­ç»ƒè„šæœ¬ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    print()
    
    print("ğŸ“‹ 1. æ£€æŸ¥é…ç½®æ–‡ä»¶")
    config_file = Path("../simple_config.json")
    if config_file.exists():
        print(f"âœ… é…ç½®æ–‡ä»¶å­˜åœ¨: {config_file.absolute()}")
        
        # è¯»å–å¹¶æ˜¾ç¤ºå…³é”®é…ç½®
        sys.path.append(str(Path(__file__).parent.parent / 'utils'))
        from config_manager import ConfigManager
        
        config_manager = ConfigManager(str(config_file))
        config = config_manager.get_config()
        
        print(f"   - æ¨¡å‹: {config.model.model_name}")
        print(f"   - RoPEç¦ç”¨å±‚: {config.model.no_rope_layers}")
        print(f"   - æ•°æ®é›†: {config.data.dataset_name}")
        print(f"   - æ‰¹æ¬¡å¤§å°: {config.training.batch_size}")
        print(f"   - å­¦ä¹ ç‡: {config.training.learning_rate}")
        print(f"   - è®­ç»ƒè½®æ•°: {config.training.num_epochs}")
        print(f"   - GPUè®¾å¤‡: {config.environment.gpu_ids}")
    else:
        print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file.absolute()}")
        print("   è¯·å…ˆè¿è¡Œäº¤äº’å¼é…ç½®æˆ–æ‰‹åŠ¨åˆ›å»ºé…ç½®æ–‡ä»¶")
    
    print()
    print("ğŸ“‹ 2. è¿è¡Œè®­ç»ƒè„šæœ¬")
    print("   å‘½ä»¤: python train_lora_rope.py")
    print("   è¯´æ˜: è„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹é…ç½®æ–‡ä»¶å¹¶å¯åŠ¨è®­ç»ƒ")
    print()
    
    print("ğŸ“‹ 3. é¢„æœŸè¾“å‡º")
    print("   - æ¨¡å‹å’Œåˆ†è¯å™¨åŠ è½½")
    print("   - RoPEå±‚ç¦ç”¨ç¡®è®¤")
    print("   - LoRAé…ç½®åº”ç”¨")
    print("   - å¯è®­ç»ƒå‚æ•°ç»Ÿè®¡")
    print("   - è®­ç»ƒè¿›åº¦æ˜¾ç¤º")
    print("   - æ¨¡å‹ä¿å­˜åˆ° /work/xiaoyonggao/{experiment_name}_lora/")
    print()
    
    print("ğŸ“‹ 4. LoRAä¼˜åŠ¿")
    print("   - å¤§å¹…å‡å°‘å¯è®­ç»ƒå‚æ•°ï¼ˆé€šå¸¸<1%ï¼‰")
    print("   - æ˜¾è‘—é™ä½æ˜¾å­˜éœ€æ±‚")
    print("   - åŠ å¿«è®­ç»ƒé€Ÿåº¦")
    print("   - ä¿æŒæ¨¡å‹æ€§èƒ½")
    print()
    
    print("ğŸ“‹ 5. è¾“å‡ºæ–‡ä»¶")
    print("   - final_lora_model/: LoRAæƒé‡å’Œé…ç½®")
    print("   - adapter_config.json: LoRAé…ç½®æ–‡ä»¶")
    print("   - adapter_model.safetensors: LoRAæƒé‡æ–‡ä»¶")
    print("   - training_config.json: è®­ç»ƒé…ç½®å¤‡ä»½")
    print()
    
    print("ğŸ“‹ 6. ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹")
    print("   ```python")
    print("   from peft import PeftModel")
    print("   from transformers import AutoModelForCausalLM")
    print("   ")
    print("   # åŠ è½½åŸºç¡€æ¨¡å‹")
    print("   base_model = AutoModelForCausalLM.from_pretrained('Qwen/Qwen2.5-3B')")
    print("   ")
    print("   # åŠ è½½LoRAæƒé‡")
    print("   model = PeftModel.from_pretrained(base_model, '/path/to/lora/model')")
    print("   ```")
    print()


def check_dependencies():
    """æ£€æŸ¥ä¾èµ–"""
    print("ğŸ” æ£€æŸ¥ä¾èµ–...")
    
    try:
        import torch
        print(f"âœ… PyTorch: {torch.__version__}")
        
        import transformers
        print(f"âœ… Transformers: {transformers.__version__}")
        
        import peft
        print(f"âœ… PEFT: {peft.__version__}")
        
        if torch.cuda.is_available():
            print(f"âœ… CUDA: å¯ç”¨ï¼Œ{torch.cuda.device_count()} GPU")
        else:
            print("âš ï¸ CUDA: ä¸å¯ç”¨")
        
        return True
        
    except ImportError as e:
        print(f"âŒ ä¾èµ–ç¼ºå¤±: {e}")
        print("è¯·å®‰è£…ç¼ºå¤±çš„ä¾èµ–:")
        print("pip install torch transformers peft")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ§ª LoRA + RoPE è®­ç»ƒç¯å¢ƒæ£€æŸ¥")
    print("=" * 60)
    print()
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        return
    
    print()
    
    # æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹
    show_usage_example()
    
    print("=" * 60)
    print("ğŸ¯ å‡†å¤‡å°±ç»ªï¼å¯ä»¥å¼€å§‹LoRAè®­ç»ƒ")
    print("=" * 60)
    print()
    print("ä¸‹ä¸€æ­¥:")
    print("1. ç¡®è®¤é…ç½®æ–‡ä»¶è®¾ç½®æ­£ç¡®")
    print("2. è¿è¡Œ: python train_lora_rope.py")
    print("3. ç­‰å¾…è®­ç»ƒå®Œæˆ")
    print("4. ä½¿ç”¨ä¿å­˜çš„LoRAæ¨¡å‹è¿›è¡Œæ¨ç†")


if __name__ == "__main__":
    main()